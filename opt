{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import time\n",
    "plt.style.use('seaborn-notebook')\n",
    "%matplotlib inline\n",
    "\n",
    "# JUST TO MAKE SURE SOME WARNINGS ARE IGNORED \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "class DECore(object):\n",
    "    \"\"\"\n",
    "    Core Class of Differential Evolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 objective_function: callable,\n",
    "                 ndim: int,\n",
    "                 lower_limit: np.ndarray,\n",
    "                 upper_limit: np.ndarray,\n",
    "                 minimize: bool = True):\n",
    "\n",
    "        \"\"\"\n",
    "        :param objective_function: f(x) callable function\n",
    "        :param ndim: dimension of x\n",
    "        :param lower_limit: lower limit of search space 1d-array\n",
    "        :param upper_limit: upper limit of search space 1d-array\n",
    "        :param minimize: minimize flag. if the problem is minimization, then set True.\n",
    "                                        otherwise set False and turning as maximization.\n",
    "        \"\"\"\n",
    "        self._of = objective_function\n",
    "        self._pop = None\n",
    "        self._nd = ndim\n",
    "        self._x_current = None\n",
    "        self._low_lim = lower_limit\n",
    "        self._up_lim = upper_limit\n",
    "        self._f_current = None\n",
    "        self._is_minimize = minimize\n",
    "        self._orbit = None\n",
    "\n",
    "    def initialization(self, x_init=None):\n",
    "        \"\"\"\n",
    "        :param x_init: initial value of x (optional)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # initialize x\n",
    "        if x_init:\n",
    "            self._x_current = x_init\n",
    "        else:\n",
    "            self._x_current = np.random.rand(self._pop, self._nd) * (self._up_lim - self._low_lim) + self._low_lim\n",
    "\n",
    "        # initialize orbit\n",
    "        self._orbit = []\n",
    "\n",
    "    def _selection(self, **kwargs):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _mutation(self, **kwargs):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _crossover(self, **kwargs):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _mutation_crossover(self, **kwargs):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _evaluate_with_check(self, x):\n",
    "        if np.any(x < self._low_lim) or np.any(x > self._up_lim):\n",
    "            return np.inf if self._is_minimize else -np.inf\n",
    "        else:\n",
    "            try:\n",
    "                f = self._of(x)\n",
    "            except Exception as ex:\n",
    "                logger.error(ex)\n",
    "                f = np.inf if self._is_minimize else -np.inf\n",
    "            return f\n",
    "\n",
    "    def _evaluate(self, params):\n",
    "        current, u = params\n",
    "        return current, self._evaluate_with_check(u)\n",
    "\n",
    "    def optimize_mp(self, **kwargs):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def optimize(self, **kwargs):\n",
    "\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def orbit(self):\n",
    "        return self._orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent import futures\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "class DE(DECore):\n",
    "    \"\"\"\n",
    "    Differential Evolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 objective_function: callable,\n",
    "                 ndim: int,\n",
    "                 lower_limit: np.ndarray,\n",
    "                 upper_limit: np.ndarray,\n",
    "                 minimize: bool = True):\n",
    "        \"\"\"\n",
    "        :param objective_function: f(x) callable function\n",
    "        :param ndim: dimension of x\n",
    "        :param lower_limit: lower limit of search space 1d-array\n",
    "        :param upper_limit: upper limit of search space 1d-array\n",
    "        :param minimize: minimize flag. if the problem is minimization, then set True.\n",
    "                                        otherwise set False and turning as maximization.\n",
    "        \"\"\"\n",
    "\n",
    "        super(DE, self).__init__(objective_function=objective_function,\n",
    "                                 ndim=ndim,\n",
    "                                 lower_limit=lower_limit,\n",
    "                                 upper_limit=upper_limit,\n",
    "                                 minimize=minimize)\n",
    "\n",
    "    def _selection(self, p, u):\n",
    "        \"\"\"\n",
    "        :param p: current index\n",
    "        :param u: trial vectors\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        fu = self._evaluate_with_check(u)\n",
    "\n",
    "        # score is better than current\n",
    "        q1 = fu <= self._f_current[p] if self._is_minimize else fu >= self._f_current[p]\n",
    "        # over lower limit\n",
    "        q2 = np.any(u < self._low_lim)\n",
    "        # over upper limit\n",
    "        q3 = np.any(u > self._up_lim)\n",
    "        # q1 ^ ~q2 ^ ~q3\n",
    "        q = q1 * ~q2 * ~q3\n",
    "\n",
    "        f_p1 = fu if q else self._f_current[p]\n",
    "        x_p1 = u if q else self._x_current[p]\n",
    "        return p, f_p1, x_p1\n",
    "\n",
    "    def _mutation(self, current, mutant, num, sf):\n",
    "        \"\"\"\n",
    "        :param current: current index of population\n",
    "        :param mutant: mutation method\n",
    "        :param num: number of mutant vectors\n",
    "        :param sf: scaling factor\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        assert num > 0, \"'num' must be greater than 0.\"\n",
    "\n",
    "        # mutant vector\n",
    "        # best\n",
    "        if mutant == 'best':\n",
    "            r_best = np.argmin(self._f_current) if self._is_minimize else np.argmax(self._f_current)\n",
    "            r = [r_best]\n",
    "            r += np.random.choice([n for n in range(self._pop) if n != r_best], 2 * num, replace=False).tolist()\n",
    "            v = self._x_current[r[0]] \\\n",
    "                + sf * np.sum([self._x_current[r[m + 1]] - self._x_current[r[m + 2]] for m in range(num)], axis=0)\n",
    "\n",
    "        # rand\n",
    "        elif mutant == 'rand':\n",
    "            r = np.random.choice(range(self._pop), 2 * num + 1, replace=False).tolist()\n",
    "            v = self._x_current[r[0]] \\\n",
    "                + sf * np.sum([self._x_current[r[m + 1]] - self._x_current[r[m + 2]] for m in range(num)], axis=0)\n",
    "\n",
    "        # current-to-rand\n",
    "        elif mutant == 'current-to-rand':\n",
    "            r = [current]\n",
    "            r += np.random.choice([n for n in range(self._pop) if n != current], 2 * num + 1, replace=False).tolist()\n",
    "            v = self._x_current[r[0]] \\\n",
    "                + sf * (self._x_current[r[1]] - self._x_current[r[0]]) \\\n",
    "                + sf * np.sum([self._x_current[r[m + 2]] - self._x_current[r[m + 3]] for m in range(num)], axis=0)\n",
    "\n",
    "        # current-to-best\n",
    "        elif mutant == 'current-to-best':\n",
    "            r_best = np.argmin(self._f_current) if self._is_minimize else np.argmax(self._f_current)\n",
    "            r = [r_best, current]\n",
    "            r += np.random.choice([\n",
    "                n for n in range(self._pop) if n not in [r_best, current]], 2 * num, replace=False).tolist()\n",
    "            v = self._x_current[r[0]] \\\n",
    "                + sf * (self._x_current[r[1]] - self._x_current[r[0]]) \\\n",
    "                + sf * np.sum([self._x_current[r[m + 2]] - self._x_current[r[m + 3]] for m in range(num)], axis=0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('invalid `mutant`: {}'.format(mutant))\n",
    "\n",
    "        return v\n",
    "\n",
    "    def _crossover(self, v, x, cross, cr):\n",
    "        \"\"\"\n",
    "        :param v: mutant vector\n",
    "        :param x: current vector\n",
    "        :param cross: crossover method\n",
    "        :param cr: crossover-rate\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # crossover\n",
    "        r = np.random.choice(range(self._nd))\n",
    "        u = np.zeros(self._nd)\n",
    "\n",
    "        # binary crossover\n",
    "        if cross == 'bin':\n",
    "            flg = np.equal(r, np.arange(self._nd)) + np.random.rand(self._nd) < cr\n",
    "\n",
    "        # exponential crossover\n",
    "        elif cross == 'exp':\n",
    "            flg = np.array([False for _ in range(self._nd)])\n",
    "            for l in range(self._nd):\n",
    "                flg[r] = True\n",
    "                r = (r + 1) % self._nd\n",
    "                if np.random.rand() >= cr:\n",
    "                    break\n",
    "        else:\n",
    "            raise ValueError('invalid `cross`: {}'.format(cross))\n",
    "\n",
    "        # from mutant vector\n",
    "        u[flg] = v[flg]\n",
    "        # from current vector\n",
    "        u[~flg] = x[~flg]\n",
    "\n",
    "        return u\n",
    "\n",
    "    def _mutation_crossover(self, mutant, num, sf, cross, cr):\n",
    "        l_up = []\n",
    "        # for each individuals\n",
    "        for p in range(self._pop):\n",
    "            # mutation\n",
    "            v_p = self._mutation(p, mutant=mutant, num=num, sf=sf)\n",
    "\n",
    "            # crossover\n",
    "            u_p = self._crossover(v_p, self._x_current[p], cross=cross, cr=cr)\n",
    "            l_up.append(u_p)\n",
    "\n",
    "        return l_up\n",
    "\n",
    "    def optimize_mp(self,\n",
    "                    k_max: int,\n",
    "                    population: int = 5,\n",
    "                    mutant: str = 'best',\n",
    "                    num: int = 1,\n",
    "                    cross: str = 'bin',\n",
    "                    sf: float = 0.7,\n",
    "                    cr: float = 0.3,\n",
    "                    proc: [int, None] = None):\n",
    "        \"\"\"\n",
    "        :param k_max: max-iterations\n",
    "        :param population: number of populations\n",
    "        :param mutant: mutation method ['best', 'rand', 'current-to-best', 'current-to-rand']\n",
    "        :param num: number of mutant vectors\n",
    "        :param cross: crossover method ['bin', 'exp']\n",
    "        :param sf: scaling-factor F\n",
    "        :param cr: crossover-rate CR\n",
    "        :param proc: number of process. if None, then use maximum process\n",
    "        :return:\n",
    "        ex) DE/rand/1/bin --> method='rand', num=1, cross='bin'\n",
    "            DE/best/2/exp --> method='best', num=2, cross='exp'\n",
    "        \"\"\"\n",
    "        # set population\n",
    "        self._pop = population\n",
    "\n",
    "        # initialize\n",
    "        self.initialization()\n",
    "\n",
    "        # get fitness of initial x\n",
    "        with futures.ProcessPoolExecutor(proc) as executor:\n",
    "            results = executor.map(self._evaluate, zip(range(self._pop), self._x_current))\n",
    "   \n",
    "        self._f_current = np.array([r[1] for r in sorted(list(results))])\n",
    "\n",
    "        for k in range(k_max):\n",
    "            # mutation and crossover\n",
    "            l_up = self._mutation_crossover(mutant, num, sf, cross, cr)\n",
    "\n",
    "            # multi-processing\n",
    "            with futures.ProcessPoolExecutor(proc) as executor:\n",
    "                results = executor.map(self._selection, range(self._pop), l_up)\n",
    "\n",
    "            # correct results\n",
    "            _x_current = []\n",
    "            _f_current = []\n",
    "            for _, fp, x in sorted(results):\n",
    "                _x_current.append(x)\n",
    "                _f_current.append(fp)\n",
    "\n",
    "            # update current values\n",
    "            self._x_current = np.r_[_x_current].copy()\n",
    "            self._f_current = np.array(_f_current).copy()\n",
    "\n",
    "            best_score = np.amin(self._f_current) if self._is_minimize else np.amax(self._f_current)\n",
    "            logger.info('k={} best score = {}'.format(k, best_score))\n",
    "            self._orbit.append(best_score)\n",
    "\n",
    "        # get best point\n",
    "        best_idx = np.argmin(self._f_current) if self._is_minimize else np.argmax(self._f_current)\n",
    "        x_best = self._x_current[best_idx]\n",
    "        logger.info('global best score = {}'.format(self._f_current[best_idx]))\n",
    "        logger.info('x_best = {}'.format(x_best))\n",
    "        \n",
    "        return x_best\n",
    "\n",
    "    def optimize(self,\n",
    "                 k_max: int,\n",
    "                 population: int = 20,\n",
    "                 mutant: str = 'best',\n",
    "                 num: int = 1,\n",
    "                 cross: str = 'bin',\n",
    "                 sf: float = 0.7,\n",
    "                 cr: float = 0.3):\n",
    "        \"\"\"\n",
    "        :param k_max: max-iterations\n",
    "        :param population: number of populations\n",
    "        :param mutant: mutation method ['best', 'rand', 'current-to-best', 'current-to-rand']\n",
    "        :param num: number of mutant vectors\n",
    "        :param cross: crossover method ['bin', 'exp']\n",
    "        :param sf: scaling-factor F\n",
    "        :param cr: crossover-rate CR\n",
    "        :return:\n",
    "        ex) DE/rand/1/bin --> method='rand', num=1, cross='bin'\n",
    "            DE/best/2/exp --> method='best', num=2, cross='exp'\n",
    "        \"\"\"\n",
    "        # set population\n",
    "        self._pop = population\n",
    "\n",
    "        # initialize\n",
    "        self.initialization()\n",
    "\n",
    "        # get fitness of initial x\n",
    "        self._f_current = np.array([self._evaluate_with_check(x) for x in self._x_current])\n",
    "\n",
    "        for k in range(k_max):\n",
    "            # mutation and crossover\n",
    "            l_up = self._mutation_crossover(mutant, num, sf, cross, cr)\n",
    "\n",
    "            for p, u_p in enumerate(l_up):\n",
    "                # selection\n",
    "                _, f_p1, x_p1 = self._selection(p, u_p)\n",
    "\n",
    "                # update current values\n",
    "                self._f_current[p] = f_p1\n",
    "                self._x_current[p] = x_p1\n",
    "\n",
    "            best_score = np.amin(self._f_current) if self._is_minimize else np.amax(self._f_current)\n",
    "            logger.info('k={} best score = {}'.format(k, best_score))\n",
    "            self._orbit.append(best_score)\n",
    "\n",
    "        # get best point\n",
    "        best_idx = np.argmin(self._f_current) if self._is_minimize else np.argmax(self._f_current)\n",
    "        x_best = self._x_current[best_idx]\n",
    "        logger.info('global best score = {}'.format(self._f_current[best_idx]))\n",
    "        logger.info('x_best = {}'.format(x_best))\n",
    "        return x_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ag_data = pd.read_csv('Ag_ordered_dataset.csv',  index_col = 0)\n",
    "shape_set = Ag_data['Shape'].unique()\n",
    "\n",
    "# Use label encoder to transform the label shape\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(shape_set)\n",
    "normalised_shape = le.transform(Ag_data['Shape']) \n",
    "\n",
    "Ag_data['Shape'] = normalised_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Ag_data.iloc[:, :79]\n",
    "y = Ag_data['Shape']\n",
    "y = np.array(y)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "dataset = load_digits()\n",
    "print(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.7042378673957621\n",
      "INFO:__main__:k=1 best score = 0.7042378673957621\n",
      "INFO:__main__:k=2 best score = 0.7303485987696515\n",
      "INFO:__main__:k=3 best score = 0.7355434039644566\n",
      "INFO:__main__:k=4 best score = 0.746308954203691\n",
      "INFO:__main__:k=5 best score = 0.746308954203691\n",
      "INFO:__main__:k=6 best score = 0.746308954203691\n",
      "INFO:__main__:k=7 best score = 0.746308954203691\n",
      "INFO:__main__:k=8 best score = 0.746308954203691\n",
      "INFO:__main__:k=9 best score = 0.746308954203691\n",
      "INFO:__main__:k=10 best score = 0.746308954203691\n",
      "INFO:__main__:k=11 best score = 0.746308954203691\n",
      "INFO:__main__:k=12 best score = 0.7488038277511962\n",
      "INFO:__main__:k=13 best score = 0.7488038277511962\n",
      "INFO:__main__:k=14 best score = 0.7514354066985647\n",
      "INFO:__main__:k=15 best score = 0.7514354066985647\n",
      "INFO:__main__:k=16 best score = 0.7592617908407382\n",
      "INFO:__main__:k=17 best score = 0.7592617908407382\n",
      "INFO:__main__:k=18 best score = 0.7592617908407382\n",
      "INFO:__main__:k=19 best score = 0.7592617908407382\n",
      "INFO:__main__:k=20 best score = 0.7592617908407382\n",
      "INFO:__main__:k=21 best score = 0.7617908407382091\n",
      "INFO:__main__:k=22 best score = 0.7617908407382091\n",
      "INFO:__main__:k=23 best score = 0.7617908407382091\n",
      "INFO:__main__:k=24 best score = 0.7721804511278195\n",
      "INFO:__main__:k=25 best score = 0.7721804511278195\n",
      "INFO:__main__:k=26 best score = 0.7721804511278195\n",
      "INFO:__main__:k=27 best score = 0.7721804511278195\n",
      "INFO:__main__:k=28 best score = 0.7721804511278195\n",
      "INFO:__main__:k=29 best score = 0.7721804511278195\n",
      "INFO:__main__:k=30 best score = 0.7721804511278195\n",
      "INFO:__main__:k=31 best score = 0.7721804511278195\n",
      "INFO:__main__:k=32 best score = 0.7721804511278195\n",
      "INFO:__main__:k=33 best score = 0.7798359535201641\n",
      "INFO:__main__:k=34 best score = 0.7798359535201641\n",
      "INFO:__main__:k=35 best score = 0.7798359535201641\n",
      "INFO:__main__:k=36 best score = 0.7798359535201641\n",
      "INFO:__main__:k=37 best score = 0.7798359535201641\n",
      "INFO:__main__:k=38 best score = 0.7798359535201641\n",
      "INFO:__main__:k=39 best score = 0.7798359535201641\n",
      "INFO:__main__:k=40 best score = 0.7798359535201641\n",
      "INFO:__main__:k=41 best score = 0.7798359535201641\n",
      "INFO:__main__:k=42 best score = 0.7798359535201641\n",
      "INFO:__main__:k=43 best score = 0.7798359535201641\n",
      "INFO:__main__:k=44 best score = 0.7798359535201641\n",
      "INFO:__main__:k=45 best score = 0.7798359535201641\n",
      "INFO:__main__:k=46 best score = 0.7798359535201641\n",
      "INFO:__main__:k=47 best score = 0.7798359535201641\n",
      "INFO:__main__:k=48 best score = 0.7798359535201641\n",
      "INFO:__main__:k=49 best score = 0.7798359535201641\n",
      "INFO:__main__:global best score = 0.7798359535201641\n",
      "INFO:__main__:x_best = [9.42174455 9.84685532 3.8937028  3.38597637]\n",
      "INFO:__main__:best parameter = {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tempfile import TemporaryDirectory\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from logging import getLogger, basicConfig\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "class HyperTuner(object):\n",
    "    def __init__(self, model, space: dict, k_fold: int = 5, **params):\n",
    "        \"\"\"\n",
    "        :param model: target model\n",
    "        :param space: search space\n",
    "        :param k_fold: number of folders for K-fold CV\n",
    "        :param params: parameters for optimizer\n",
    "        space = {\n",
    "            'parameter': {'scale': linear', 'range': [0, 1.5]},\n",
    "            'parameter': {'scale': 'log', 'range': [-1, 2]},\n",
    "            'parameter': {'scale': 'category', 'range': ['a', 'b', 'c']},\n",
    "            'parameter': {'scale': 'integer', 'range': [0, 10]},\n",
    "            'parameter': 'static'\n",
    "        }\n",
    "        \"\"\"\n",
    "        self._model = model\n",
    "        assert isinstance(space, dict)\n",
    "        self._space = space\n",
    "        self._parameters = list(self._space.keys())\n",
    "        self._static_params = [p for p in self._parameters if not isinstance(self._space[p], dict)]\n",
    "        self._variable_params = [p for p in self._parameters if isinstance(self._space[p], dict)]\n",
    "        self._tempdir = TemporaryDirectory()\n",
    "        self._tempfile = Path(self._tempdir.name + 'temp_data.gz')\n",
    "        self._eval_function = None\n",
    "        default_opt_param = {'k_max': 50,\n",
    "                             'population': 10,\n",
    "                             'mutant': 'best',\n",
    "                             'num': 1,\n",
    "                             'cross': 'bin',\n",
    "                             'sf': 0.7,\n",
    "                             'cr': 0.4}\n",
    "        self._optimizer_param = default_opt_param\n",
    "        self._optimizer_param.update(params)\n",
    "        self._kf = k_fold\n",
    "\n",
    "    def __del__(self):\n",
    "        self._tempdir.cleanup()\n",
    "\n",
    "    def _get_search_limits(self):\n",
    "        lowers = []\n",
    "        uppers = []\n",
    "        for k in self._variable_params:\n",
    "            if self._space[k]['scale'] in ['linear', 'log']:\n",
    "                lowers.append(self._space[k]['range'][0])\n",
    "                uppers.append(self._space[k]['range'][1])\n",
    "            elif self._space[k]['scale'] == 'integer':\n",
    "                lowers.append(self._space[k]['range'][0])\n",
    "                uppers.append(self._space[k]['range'][1] + 1)\n",
    "            else:\n",
    "                lowers.append(0)\n",
    "                uppers.append(len(self._space[k]['range']))\n",
    "\n",
    "        return np.array(lowers), np.array(uppers)\n",
    "\n",
    "    def _translate_to_origin(self, x):\n",
    "        org_x = {}\n",
    "        for n, k in enumerate(self._variable_params):\n",
    "            if self._space[k]['scale'] == 'log':\n",
    "                org_x[k] = np.power(10, x[n])\n",
    "            elif self._space[k]['scale'] == 'category':\n",
    "                org_x[k] = self._space[k]['range'][int(x[n])]\n",
    "            elif self._space[k]['scale'] == 'integer':\n",
    "                org_x[k] = int(x[n])\n",
    "            else:\n",
    "                org_x[k] = x[n]\n",
    "\n",
    "        # static parameters\n",
    "        for k in self._static_params:\n",
    "            org_x[k] = self._space[k]\n",
    "        return org_x\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        # load data from temporary directory\n",
    "        input_data, targets = joblib.load(self._tempfile)\n",
    "\n",
    "        # set model using parameter x\n",
    "        param = self._translate_to_origin(x)\n",
    "        model = self._model.set_params(**param)\n",
    "\n",
    "        # train model using CV (K-fold)\n",
    "        skf = KFold(n_splits=self._kf, shuffle=True)\n",
    "        scores = []\n",
    "        for train, test in skf.split(input_data, targets):\n",
    "            x_tr, t_tr = input_data[train], targets[train]\n",
    "            x_te, t_te = input_data[test], targets[test]\n",
    "\n",
    "            model.fit(x_tr, t_tr)\n",
    "            scores.append(self._eval_function(y_pred=model.predict(x_te), y_true=t_te))\n",
    "\n",
    "        # average score\n",
    "        return np.average(scores)\n",
    "\n",
    "    def tuning(self, eval_function: callable, x: np.ndarray, t: np.ndarray, minimize: bool = True):\n",
    "        joblib.dump((x, t), self._tempfile)\n",
    "\n",
    "        # set DE\n",
    "        lower_limit, upper_limit = self._get_search_limits()\n",
    "\n",
    "        # set evaluation function\n",
    "        self._eval_function = eval_function\n",
    "        optimizer = DE(objective_function=self._evaluate, ndim=len(lower_limit), lower_limit=lower_limit,\n",
    "                       upper_limit=upper_limit, minimize=minimize)\n",
    "\n",
    "        x_best = optimizer.optimize_mp(**self._optimizer_param)\n",
    "\n",
    "        return self._translate_to_origin(x_best)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    basicConfig(level='INFO')\n",
    "\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': {'scale': 'integer', 'range': [1, 10]},\n",
    "        'min_samples_split': {'scale': 'integer', 'range': [2, 10]},\n",
    "        'min_samples_leaf': {'scale': 'integer', 'range': [1, 10]},\n",
    "        'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}\n",
    "    }\n",
    "\n",
    "    tuner = HyperTuner(model= RandomForestClassifier(random_state =1), space=search_space)\n",
    "    best_param = tuner.tuning(eval_function=accuracy_score, x=X_train, t=y_train, minimize=False)\n",
    "    time_end=time.time()\n",
    "    logger.info('best parameter = {}'.format(best_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**population: 20, inter: 50**\n",
    "\n",
    "**Search Space:** max_depth: 1~10, \n",
    "min_samples_split: 2~10, min_samples_leaf: 1~10, max_features: auto, sqrt, log2, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth = 12, max_features = None, min_samples_leaf = 2, min_samples_split = 5, random_state = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {'max_depth': [1,2,3,4,5,6,7,8,9,10, 11, 12, 13, 14, 15],\n",
    "                'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "                'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10],\n",
    "                'max_features': ('auto', 'sqrt', 'log2', None)}\n",
    "\n",
    "time_start=time.time()\n",
    "clf = RandomizedSearchCV(RandomForestClassifier(random_state = 1), search_space, cv = 5, n_iter = 100)\n",
    "clf.fit(X, y)\n",
    "time_end=time.time()\n",
    "\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "# print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth = 9, max_features = None, min_samples_leaf = 4, min_samples_split = 6, random_state = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 563.1987788677216 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state = 1), search_space, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "time_end=time.time()\n",
    "\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "# print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209302325581395"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth = 10, max_features = None, min_samples_leaf = 1, min_samples_split = 3, random_state = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space1 = {'max_depth': [1,2],\n",
    "                'min_samples_split':[2,3],\n",
    "                'min_samples_leaf': [1,2],\n",
    "                'max_features': ('auto', 'sqrt', 'log2', None)}\n",
    "\n",
    "search_space2 = {'max_depth': [1,2,3,4],\n",
    "                'min_samples_split':[2,3,4,5],\n",
    "                'min_samples_leaf': [1,2,3,4],\n",
    "                'max_features': ('auto', 'sqrt', 'log2', None)}\n",
    "\n",
    "search_space3 = {'max_depth': [1,2,3,4,5,6],\n",
    "                'min_samples_split':[2,3,4,5,6,7],\n",
    "                'min_samples_leaf': [1,2,3,4,5,6],\n",
    "                'max_features': ('auto', 'sqrt', 'log2', None)}\n",
    "\n",
    "search_space4 = {'max_depth': [1,2,3,4,5,6,7,8],\n",
    "                'min_samples_split':[2,3,4,5,6,7,8,9],\n",
    "                'min_samples_leaf': [1,2,3,4,5,6,7,8],\n",
    "                'max_features': ('auto', 'sqrt', 'log2', None)}\n",
    " \n",
    "search_space5 = {'max_depth': [1,2,3,4,5,6,7,8,9,10],\n",
    "                'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "                'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10],\n",
    "                'max_features': ('auto', 'sqrt', 'log2', None)}\n",
    "\n",
    "search_spaces = []\n",
    "search_spaces.append(search_space1)\n",
    "search_spaces.append(search_space2)\n",
    "search_spaces.append(search_space3)\n",
    "search_spaces.append(search_space4)\n",
    "#search_spaces.append(search_space5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for our SaDE+SearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters: \n",
    "\n",
    "1.\tCriterion: ‘gini’, ‘entropy’\n",
    "2.\tSplitter: ‘best’, ‘random’\n",
    "3.\tMax_features: ‘auto’, ‘sqrt’, ‘log2’\n",
    "4.\tMax_depth: int\n",
    "5.\tMax_samples_split: int or float\n",
    "6.\tMax_samples_leaf: int or float\n",
    "7.\tMax_leaf_nodes: int\n",
    "\n",
    "10 tests for this model. \n",
    "\n",
    "Test cases:\n",
    "\n",
    "Test 1: Max_depth: 1~3, Max_Samples_split: 2~3, Max_samples_leaf: 1~3, Max_leaf_nodes: 1~3\n",
    "\n",
    "Test 2: Max_depth: 1~6, Max_Samples_split: 2~6, Max_samples_leaf: 1~6, Max_leaf_nodes: 1~6\n",
    "\n",
    "Test 3: Max_depth: 1~9, Max_Samples_split: 2~9, Max_samples_leaf: 1~9, Max_leaf_nodes: 1~9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': {'scale': 'integer', 'range': [1, 3]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 3]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 3]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 3]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 6]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 6]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 6]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 6]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 9]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 9]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 9]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 9]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 12]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 12]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 12]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 12]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 15]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 15]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 15]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 15]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 18]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 18]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 18]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 18]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 21]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 21]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 21]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 21]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 24]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 24]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 24]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 24]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 27]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 27]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 27]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 27]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}},\n",
       " {'max_depth': {'scale': 'integer', 'range': [1, 30]},\n",
       "  'min_samples_split': {'scale': 'integer', 'range': [2, 30]},\n",
       "  'min_samples_leaf': {'scale': 'integer', 'range': [1, 30]},\n",
       "  'max_leaf_nodes': {'scale': 'integer', 'range': [2, 30]},\n",
       "  'max_features': {'scale': 'category',\n",
       "   'range': ['auto', 'sqrt', 'log2', None]}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space1 = {'max_depth': {'scale': 'integer', 'range': [1, 3]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 3]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 3]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 3]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space2 = {'max_depth': {'scale': 'integer', 'range': [1, 6]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 6]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 6]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 6]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space3 = {'max_depth': {'scale': 'integer', 'range': [1, 9]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 9]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 9]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 9]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space4 = {'max_depth': {'scale': 'integer', 'range': [1, 12]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 12]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 12]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 12]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space5 = {'max_depth': {'scale': 'integer', 'range': [1, 15]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 15]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 15]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 15]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space6 = {'max_depth': {'scale': 'integer', 'range': [1, 18]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 18]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 18]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 18]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space7 = {'max_depth': {'scale': 'integer', 'range': [1, 21]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 21]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 21]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 21]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space8 = {'max_depth': {'scale': 'integer', 'range': [1, 24]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 24]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 24]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 24]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space9 = {'max_depth': {'scale': 'integer', 'range': [1, 27]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 27]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 27]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 27]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_space10 = {'max_depth': {'scale': 'integer', 'range': [1, 30]},\n",
    "                'min_samples_split': {'scale': 'integer', 'range': [2, 30]},\n",
    "                'min_samples_leaf': {'scale': 'integer', 'range': [1, 30]},\n",
    "                'max_leaf_nodes':{'scale': 'integer', 'range': [2, 30]},\n",
    "                'max_features': {'scale': 'category', 'range': ['auto', 'sqrt', 'log2', None]}}\n",
    "\n",
    "search_spaces_for_DE = []\n",
    "search_spaces_for_DE.append(search_space1)\n",
    "search_spaces_for_DE.append(search_space2)\n",
    "search_spaces_for_DE.append(search_space3)\n",
    "search_spaces_for_DE.append(search_space4)\n",
    "search_spaces_for_DE.append(search_space5)\n",
    "search_spaces_for_DE.append(search_space6)\n",
    "search_spaces_for_DE.append(search_space7)\n",
    "search_spaces_for_DE.append(search_space8)\n",
    "search_spaces_for_DE.append(search_space9)\n",
    "search_spaces_for_DE.append(search_space10)\n",
    "\n",
    "search_spaces_for_DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.5261107313738893\n",
      "INFO:__main__:k=1 best score = 0.5261107313738893\n",
      "INFO:__main__:k=2 best score = 0.5261107313738893\n",
      "INFO:__main__:k=3 best score = 0.5261107313738893\n",
      "INFO:__main__:k=4 best score = 0.5261107313738893\n",
      "INFO:__main__:k=5 best score = 0.5261107313738893\n",
      "INFO:__main__:k=6 best score = 0.5261107313738893\n",
      "INFO:__main__:k=7 best score = 0.5261107313738893\n",
      "INFO:__main__:k=8 best score = 0.5261107313738893\n",
      "INFO:__main__:k=9 best score = 0.5261107313738893\n",
      "INFO:__main__:k=10 best score = 0.526179084073821\n",
      "INFO:__main__:k=11 best score = 0.5314764183185237\n",
      "INFO:__main__:k=12 best score = 0.5314764183185237\n",
      "INFO:__main__:k=13 best score = 0.5314764183185237\n",
      "INFO:__main__:k=14 best score = 0.5314764183185237\n",
      "INFO:__main__:k=15 best score = 0.5314764183185237\n",
      "INFO:__main__:k=16 best score = 0.5314764183185237\n",
      "INFO:__main__:k=17 best score = 0.5314764183185237\n",
      "INFO:__main__:k=18 best score = 0.5314764183185237\n",
      "INFO:__main__:k=19 best score = 0.5314764183185237\n",
      "INFO:__main__:k=20 best score = 0.5314764183185237\n",
      "INFO:__main__:k=21 best score = 0.533902939166097\n",
      "INFO:__main__:k=22 best score = 0.533902939166097\n",
      "INFO:__main__:k=23 best score = 0.533902939166097\n",
      "INFO:__main__:k=24 best score = 0.533902939166097\n",
      "INFO:__main__:k=25 best score = 0.533902939166097\n",
      "INFO:__main__:k=26 best score = 0.533902939166097\n",
      "INFO:__main__:k=27 best score = 0.533902939166097\n",
      "INFO:__main__:k=28 best score = 0.533902939166097\n",
      "INFO:__main__:k=29 best score = 0.533902939166097\n",
      "INFO:__main__:k=30 best score = 0.533902939166097\n",
      "INFO:__main__:k=31 best score = 0.533902939166097\n",
      "INFO:__main__:k=32 best score = 0.533902939166097\n",
      "INFO:__main__:k=33 best score = 0.533902939166097\n",
      "INFO:__main__:k=34 best score = 0.533902939166097\n",
      "INFO:__main__:k=35 best score = 0.533902939166097\n",
      "INFO:__main__:k=36 best score = 0.533902939166097\n",
      "INFO:__main__:k=37 best score = 0.533902939166097\n",
      "INFO:__main__:k=38 best score = 0.533902939166097\n",
      "INFO:__main__:k=39 best score = 0.533902939166097\n",
      "INFO:__main__:k=40 best score = 0.533902939166097\n",
      "INFO:__main__:k=41 best score = 0.533902939166097\n",
      "INFO:__main__:k=42 best score = 0.533902939166097\n",
      "INFO:__main__:k=43 best score = 0.533902939166097\n",
      "INFO:__main__:k=44 best score = 0.533902939166097\n",
      "INFO:__main__:k=45 best score = 0.533902939166097\n",
      "INFO:__main__:k=46 best score = 0.533902939166097\n",
      "INFO:__main__:k=47 best score = 0.533902939166097\n",
      "INFO:__main__:k=48 best score = 0.533902939166097\n",
      "INFO:__main__:k=49 best score = 0.533902939166097\n",
      "INFO:__main__:global best score = 0.533902939166097\n",
      "INFO:__main__:x_best = [3.96421004 2.8632895  2.10081912 3.97268003 3.36795664]\n",
      "INFO:__main__:best parameter = {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_leaf_nodes': 3, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6097402597402597\n",
      "INFO:__main__:k=1 best score = 0.6097402597402597\n",
      "INFO:__main__:k=2 best score = 0.6097402597402597\n",
      "INFO:__main__:k=3 best score = 0.6097402597402597\n",
      "INFO:__main__:k=4 best score = 0.6097402597402597\n",
      "INFO:__main__:k=5 best score = 0.6255980861244019\n",
      "INFO:__main__:k=6 best score = 0.6255980861244019\n",
      "INFO:__main__:k=7 best score = 0.6255980861244019\n",
      "INFO:__main__:k=8 best score = 0.6255980861244019\n",
      "INFO:__main__:k=9 best score = 0.6255980861244019\n",
      "INFO:__main__:k=10 best score = 0.6413192071086808\n",
      "INFO:__main__:k=11 best score = 0.6413192071086808\n",
      "INFO:__main__:k=12 best score = 0.6413192071086808\n",
      "INFO:__main__:k=13 best score = 0.6413192071086808\n",
      "INFO:__main__:k=14 best score = 0.6413192071086808\n",
      "INFO:__main__:k=15 best score = 0.6413192071086808\n",
      "INFO:__main__:k=16 best score = 0.6413192071086808\n",
      "INFO:__main__:k=17 best score = 0.6413192071086808\n",
      "INFO:__main__:k=18 best score = 0.6413192071086808\n",
      "INFO:__main__:k=19 best score = 0.6413192071086808\n",
      "INFO:__main__:k=20 best score = 0.6413192071086808\n",
      "INFO:__main__:k=21 best score = 0.6413192071086808\n",
      "INFO:__main__:k=22 best score = 0.6413192071086808\n",
      "INFO:__main__:k=23 best score = 0.6413192071086808\n",
      "INFO:__main__:k=24 best score = 0.6413192071086808\n",
      "INFO:__main__:k=25 best score = 0.6413192071086808\n",
      "INFO:__main__:k=26 best score = 0.6413192071086808\n",
      "INFO:__main__:k=27 best score = 0.6413192071086808\n",
      "INFO:__main__:k=28 best score = 0.6413192071086808\n",
      "INFO:__main__:k=29 best score = 0.6413192071086808\n",
      "INFO:__main__:k=30 best score = 0.6413192071086808\n",
      "INFO:__main__:k=31 best score = 0.6413192071086808\n",
      "INFO:__main__:k=32 best score = 0.6413192071086808\n",
      "INFO:__main__:k=33 best score = 0.6413192071086808\n",
      "INFO:__main__:k=34 best score = 0.6413192071086808\n",
      "INFO:__main__:k=35 best score = 0.6413192071086808\n",
      "INFO:__main__:k=36 best score = 0.6413192071086808\n",
      "INFO:__main__:k=37 best score = 0.6413192071086808\n",
      "INFO:__main__:k=38 best score = 0.6413192071086808\n",
      "INFO:__main__:k=39 best score = 0.6413192071086808\n",
      "INFO:__main__:k=40 best score = 0.6413192071086808\n",
      "INFO:__main__:k=41 best score = 0.6413192071086808\n",
      "INFO:__main__:k=42 best score = 0.6413192071086808\n",
      "INFO:__main__:k=43 best score = 0.6413192071086808\n",
      "INFO:__main__:k=44 best score = 0.6413192071086808\n",
      "INFO:__main__:k=45 best score = 0.6413192071086808\n",
      "INFO:__main__:k=46 best score = 0.6413192071086808\n",
      "INFO:__main__:k=47 best score = 0.6413192071086808\n",
      "INFO:__main__:k=48 best score = 0.6413192071086808\n",
      "INFO:__main__:k=49 best score = 0.6413192071086808\n",
      "INFO:__main__:global best score = 0.6413192071086808\n",
      "INFO:__main__:x_best = [5.9577937  4.97445826 5.60543858 6.30746364 3.12880979]\n",
      "INFO:__main__:best parameter = {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_leaf_nodes': 6, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.49709501025290503\n",
      "INFO:__main__:k=1 best score = 0.5129186602870813\n",
      "INFO:__main__:k=2 best score = 0.6750170881749828\n",
      "INFO:__main__:k=3 best score = 0.6750170881749828\n",
      "INFO:__main__:k=4 best score = 0.6750170881749828\n",
      "INFO:__main__:k=5 best score = 0.6750170881749828\n",
      "INFO:__main__:k=6 best score = 0.6750170881749828\n",
      "INFO:__main__:k=7 best score = 0.6750170881749828\n",
      "INFO:__main__:k=8 best score = 0.6750170881749828\n",
      "INFO:__main__:k=9 best score = 0.6750170881749828\n",
      "INFO:__main__:k=10 best score = 0.6750170881749828\n",
      "INFO:__main__:k=11 best score = 0.6887218045112782\n",
      "INFO:__main__:k=12 best score = 0.6887218045112782\n",
      "INFO:__main__:k=13 best score = 0.6887218045112782\n",
      "INFO:__main__:k=14 best score = 0.6887218045112782\n",
      "INFO:__main__:k=15 best score = 0.6887218045112782\n",
      "INFO:__main__:k=16 best score = 0.6887218045112782\n",
      "INFO:__main__:k=17 best score = 0.6887218045112782\n",
      "INFO:__main__:k=18 best score = 0.6887218045112782\n",
      "INFO:__main__:k=19 best score = 0.6887218045112782\n",
      "INFO:__main__:k=20 best score = 0.6887218045112782\n",
      "INFO:__main__:k=21 best score = 0.6887218045112782\n",
      "INFO:__main__:k=22 best score = 0.6887218045112782\n",
      "INFO:__main__:k=23 best score = 0.6887218045112782\n",
      "INFO:__main__:k=24 best score = 0.6887218045112782\n",
      "INFO:__main__:k=25 best score = 0.6887218045112782\n",
      "INFO:__main__:k=26 best score = 0.6887218045112782\n",
      "INFO:__main__:k=27 best score = 0.6887218045112782\n",
      "INFO:__main__:k=28 best score = 0.6887218045112782\n",
      "INFO:__main__:k=29 best score = 0.6887218045112782\n",
      "INFO:__main__:k=30 best score = 0.6887218045112782\n",
      "INFO:__main__:k=31 best score = 0.6887218045112782\n",
      "INFO:__main__:k=32 best score = 0.6887218045112782\n",
      "INFO:__main__:k=33 best score = 0.6887218045112782\n",
      "INFO:__main__:k=34 best score = 0.6887218045112782\n",
      "INFO:__main__:k=35 best score = 0.6887218045112782\n",
      "INFO:__main__:k=36 best score = 0.6887218045112782\n",
      "INFO:__main__:k=37 best score = 0.6962747778537253\n",
      "INFO:__main__:k=38 best score = 0.6962747778537253\n",
      "INFO:__main__:k=39 best score = 0.6962747778537253\n",
      "INFO:__main__:k=40 best score = 0.6962747778537253\n",
      "INFO:__main__:k=41 best score = 0.6962747778537253\n",
      "INFO:__main__:k=42 best score = 0.6962747778537253\n",
      "INFO:__main__:k=43 best score = 0.6962747778537253\n",
      "INFO:__main__:k=44 best score = 0.6962747778537253\n",
      "INFO:__main__:k=45 best score = 0.6962747778537253\n",
      "INFO:__main__:k=46 best score = 0.6962747778537253\n",
      "INFO:__main__:k=47 best score = 0.6962747778537253\n",
      "INFO:__main__:k=48 best score = 0.6962747778537253\n",
      "INFO:__main__:k=49 best score = 0.6962747778537253\n",
      "INFO:__main__:global best score = 0.6962747778537253\n",
      "INFO:__main__:x_best = [9.48581983 3.80511192 1.89652584 9.70488092 3.98109033]\n",
      "INFO:__main__:best parameter = {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_leaf_nodes': 9, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6780246069719753\n",
      "INFO:__main__:k=1 best score = 0.6780246069719753\n",
      "INFO:__main__:k=2 best score = 0.6780246069719753\n",
      "INFO:__main__:k=3 best score = 0.6780246069719753\n",
      "INFO:__main__:k=4 best score = 0.6780246069719753\n",
      "INFO:__main__:k=5 best score = 0.6780246069719753\n",
      "INFO:__main__:k=6 best score = 0.6780246069719753\n",
      "INFO:__main__:k=7 best score = 0.6780246069719753\n",
      "INFO:__main__:k=8 best score = 0.6860218728639782\n",
      "INFO:__main__:k=9 best score = 0.6860218728639782\n",
      "INFO:__main__:k=10 best score = 0.6860218728639782\n",
      "INFO:__main__:k=11 best score = 0.6860218728639782\n",
      "INFO:__main__:k=12 best score = 0.6860218728639782\n",
      "INFO:__main__:k=13 best score = 0.6860218728639782\n",
      "INFO:__main__:k=14 best score = 0.6860218728639782\n",
      "INFO:__main__:k=15 best score = 0.6860218728639782\n",
      "INFO:__main__:k=16 best score = 0.6886876281613123\n",
      "INFO:__main__:k=17 best score = 0.6886876281613123\n",
      "INFO:__main__:k=18 best score = 0.6886876281613123\n",
      "INFO:__main__:k=19 best score = 0.7067327409432673\n",
      "INFO:__main__:k=20 best score = 0.7276144907723855\n",
      "INFO:__main__:k=21 best score = 0.7276144907723855\n",
      "INFO:__main__:k=22 best score = 0.7276144907723855\n",
      "INFO:__main__:k=23 best score = 0.7276144907723855\n",
      "INFO:__main__:k=24 best score = 0.7276144907723855\n",
      "INFO:__main__:k=25 best score = 0.7276144907723855\n",
      "INFO:__main__:k=26 best score = 0.7276144907723855\n",
      "INFO:__main__:k=27 best score = 0.7276144907723855\n",
      "INFO:__main__:k=28 best score = 0.7276144907723855\n",
      "INFO:__main__:k=29 best score = 0.7276144907723855\n",
      "INFO:__main__:k=30 best score = 0.7276144907723855\n",
      "INFO:__main__:k=31 best score = 0.7276144907723855\n",
      "INFO:__main__:k=32 best score = 0.7276144907723855\n",
      "INFO:__main__:k=33 best score = 0.7276144907723855\n",
      "INFO:__main__:k=34 best score = 0.7276144907723855\n",
      "INFO:__main__:k=35 best score = 0.7276144907723855\n",
      "INFO:__main__:k=36 best score = 0.7276144907723855\n",
      "INFO:__main__:k=37 best score = 0.7276144907723855\n",
      "INFO:__main__:k=38 best score = 0.7276144907723855\n",
      "INFO:__main__:k=39 best score = 0.7276144907723855\n",
      "INFO:__main__:k=40 best score = 0.7276144907723855\n",
      "INFO:__main__:k=41 best score = 0.7276144907723855\n",
      "INFO:__main__:k=42 best score = 0.7276144907723855\n",
      "INFO:__main__:k=43 best score = 0.7276144907723855\n",
      "INFO:__main__:k=44 best score = 0.7276144907723855\n",
      "INFO:__main__:k=45 best score = 0.7276144907723855\n",
      "INFO:__main__:k=46 best score = 0.7276144907723855\n",
      "INFO:__main__:k=47 best score = 0.7276144907723855\n",
      "INFO:__main__:k=48 best score = 0.7276144907723855\n",
      "INFO:__main__:k=49 best score = 0.7276144907723855\n",
      "INFO:__main__:global best score = 0.7276144907723855\n",
      "INFO:__main__:x_best = [ 4.87809846  6.10815456  1.17120517 12.09331078  3.81447292]\n",
      "INFO:__main__:best parameter = {'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_leaf_nodes': 12, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6571770334928229\n",
      "INFO:__main__:k=1 best score = 0.6571770334928229\n",
      "INFO:__main__:k=2 best score = 0.6571770334928229\n",
      "INFO:__main__:k=3 best score = 0.6961038961038961\n",
      "INFO:__main__:k=4 best score = 0.6961038961038961\n",
      "INFO:__main__:k=5 best score = 0.6961038961038961\n",
      "INFO:__main__:k=6 best score = 0.6961038961038961\n",
      "INFO:__main__:k=7 best score = 0.6961038961038961\n",
      "INFO:__main__:k=8 best score = 0.6989747095010254\n",
      "INFO:__main__:k=9 best score = 0.6989747095010254\n",
      "INFO:__main__:k=10 best score = 0.6989747095010254\n",
      "INFO:__main__:k=11 best score = 0.7043745727956254\n",
      "INFO:__main__:k=12 best score = 0.7043745727956254\n",
      "INFO:__main__:k=13 best score = 0.7043745727956254\n",
      "INFO:__main__:k=14 best score = 0.7221804511278196\n",
      "INFO:__main__:k=15 best score = 0.7224538619275461\n",
      "INFO:__main__:k=16 best score = 0.7381749829118249\n",
      "INFO:__main__:k=17 best score = 0.7381749829118249\n",
      "INFO:__main__:k=18 best score = 0.7381749829118249\n",
      "INFO:__main__:k=19 best score = 0.7381749829118249\n",
      "INFO:__main__:k=20 best score = 0.7381749829118249\n",
      "INFO:__main__:k=21 best score = 0.7381749829118249\n",
      "INFO:__main__:k=22 best score = 0.7381749829118249\n",
      "INFO:__main__:k=23 best score = 0.7381749829118249\n",
      "INFO:__main__:k=24 best score = 0.7381749829118249\n",
      "INFO:__main__:k=25 best score = 0.7381749829118249\n",
      "INFO:__main__:k=26 best score = 0.7381749829118249\n",
      "INFO:__main__:k=27 best score = 0.7381749829118249\n",
      "INFO:__main__:k=28 best score = 0.7381749829118249\n",
      "INFO:__main__:k=29 best score = 0.7381749829118249\n",
      "INFO:__main__:k=30 best score = 0.7381749829118249\n",
      "INFO:__main__:k=31 best score = 0.7381749829118249\n",
      "INFO:__main__:k=32 best score = 0.7381749829118249\n",
      "INFO:__main__:k=33 best score = 0.7381749829118249\n",
      "INFO:__main__:k=34 best score = 0.7381749829118249\n",
      "INFO:__main__:k=35 best score = 0.7381749829118249\n",
      "INFO:__main__:k=36 best score = 0.7381749829118249\n",
      "INFO:__main__:k=37 best score = 0.7382433356117566\n",
      "INFO:__main__:k=38 best score = 0.7382433356117566\n",
      "INFO:__main__:k=39 best score = 0.7382433356117566\n",
      "INFO:__main__:k=40 best score = 0.7382433356117566\n",
      "INFO:__main__:k=41 best score = 0.740909090909091\n",
      "INFO:__main__:k=42 best score = 0.740909090909091\n",
      "INFO:__main__:k=43 best score = 0.740909090909091\n",
      "INFO:__main__:k=44 best score = 0.740909090909091\n",
      "INFO:__main__:k=45 best score = 0.740909090909091\n",
      "INFO:__main__:k=46 best score = 0.7409432672590567\n",
      "INFO:__main__:k=47 best score = 0.7409432672590567\n",
      "INFO:__main__:k=48 best score = 0.7409432672590567\n",
      "INFO:__main__:k=49 best score = 0.7409432672590567\n",
      "INFO:__main__:global best score = 0.7409432672590567\n",
      "INFO:__main__:x_best = [ 7.53945248  7.84636232  3.29805897 15.75190966  3.18808592]\n",
      "INFO:__main__:best parameter = {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_leaf_nodes': 15, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6126452494873547\n",
      "INFO:__main__:k=1 best score = 0.6126452494873547\n",
      "INFO:__main__:k=2 best score = 0.6545796308954204\n",
      "INFO:__main__:k=3 best score = 0.6545796308954204\n",
      "INFO:__main__:k=4 best score = 0.6545796308954204\n",
      "INFO:__main__:k=5 best score = 0.6545796308954204\n",
      "INFO:__main__:k=6 best score = 0.6573137388926862\n",
      "INFO:__main__:k=7 best score = 0.665105946684894\n",
      "INFO:__main__:k=8 best score = 0.7092959671907041\n",
      "INFO:__main__:k=9 best score = 0.7277853725222146\n",
      "INFO:__main__:k=10 best score = 0.7277853725222146\n",
      "INFO:__main__:k=11 best score = 0.7277853725222146\n",
      "INFO:__main__:k=12 best score = 0.7277853725222146\n",
      "INFO:__main__:k=13 best score = 0.7277853725222146\n",
      "INFO:__main__:k=14 best score = 0.7277853725222146\n",
      "INFO:__main__:k=15 best score = 0.7277853725222146\n",
      "INFO:__main__:k=16 best score = 0.7277853725222146\n",
      "INFO:__main__:k=17 best score = 0.7277853725222146\n",
      "INFO:__main__:k=18 best score = 0.7305194805194806\n",
      "INFO:__main__:k=19 best score = 0.7386534518113466\n",
      "INFO:__main__:k=20 best score = 0.7386534518113466\n",
      "INFO:__main__:k=21 best score = 0.7386534518113466\n",
      "INFO:__main__:k=22 best score = 0.7410116199589885\n",
      "INFO:__main__:k=23 best score = 0.7433697881066302\n",
      "INFO:__main__:k=24 best score = 0.7433697881066302\n",
      "INFO:__main__:k=25 best score = 0.7433697881066302\n",
      "INFO:__main__:k=26 best score = 0.7433697881066302\n",
      "INFO:__main__:k=27 best score = 0.7433697881066302\n",
      "INFO:__main__:k=28 best score = 0.7433697881066302\n",
      "INFO:__main__:k=29 best score = 0.7433697881066302\n",
      "INFO:__main__:k=30 best score = 0.7433697881066302\n",
      "INFO:__main__:k=31 best score = 0.7433697881066302\n",
      "INFO:__main__:k=32 best score = 0.7433697881066302\n",
      "INFO:__main__:k=33 best score = 0.7433697881066302\n",
      "INFO:__main__:k=34 best score = 0.7433697881066302\n",
      "INFO:__main__:k=35 best score = 0.7433697881066302\n",
      "INFO:__main__:k=36 best score = 0.7433697881066302\n",
      "INFO:__main__:k=37 best score = 0.7435064935064937\n",
      "INFO:__main__:k=38 best score = 0.7435064935064937\n",
      "INFO:__main__:k=39 best score = 0.7435064935064937\n",
      "INFO:__main__:k=40 best score = 0.7435064935064937\n",
      "INFO:__main__:k=41 best score = 0.7435064935064937\n",
      "INFO:__main__:k=42 best score = 0.7435064935064937\n",
      "INFO:__main__:k=43 best score = 0.7435064935064937\n",
      "INFO:__main__:k=44 best score = 0.7486671223513329\n",
      "INFO:__main__:k=45 best score = 0.7486671223513329\n",
      "INFO:__main__:k=46 best score = 0.7486671223513329\n",
      "INFO:__main__:k=47 best score = 0.7486671223513329\n",
      "INFO:__main__:k=48 best score = 0.7486671223513329\n",
      "INFO:__main__:k=49 best score = 0.7486671223513329\n",
      "INFO:__main__:global best score = 0.7486671223513329\n",
      "INFO:__main__:x_best = [15.08214046  5.69166844  4.28284123 18.5316756   3.26827444]\n",
      "INFO:__main__:best parameter = {'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_leaf_nodes': 18, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6646274777853726\n",
      "INFO:__main__:k=1 best score = 0.7014354066985645\n",
      "INFO:__main__:k=2 best score = 0.7014354066985645\n",
      "INFO:__main__:k=3 best score = 0.7014354066985645\n",
      "INFO:__main__:k=4 best score = 0.7014354066985645\n",
      "INFO:__main__:k=5 best score = 0.7015037593984963\n",
      "INFO:__main__:k=6 best score = 0.7015037593984963\n",
      "INFO:__main__:k=7 best score = 0.7015037593984963\n",
      "INFO:__main__:k=8 best score = 0.7096719070403281\n",
      "INFO:__main__:k=9 best score = 0.7096719070403281\n",
      "INFO:__main__:k=10 best score = 0.7096719070403281\n",
      "INFO:__main__:k=11 best score = 0.7304169514695831\n",
      "INFO:__main__:k=12 best score = 0.7304169514695831\n",
      "INFO:__main__:k=13 best score = 0.7304169514695831\n",
      "INFO:__main__:k=14 best score = 0.7304169514695831\n",
      "INFO:__main__:k=15 best score = 0.7514012303485987\n",
      "INFO:__main__:k=16 best score = 0.7514012303485987\n",
      "INFO:__main__:k=17 best score = 0.7514012303485987\n",
      "INFO:__main__:k=18 best score = 0.7514012303485987\n",
      "INFO:__main__:k=19 best score = 0.7644907723855093\n",
      "INFO:__main__:k=20 best score = 0.7644907723855093\n",
      "INFO:__main__:k=21 best score = 0.7644907723855093\n",
      "INFO:__main__:k=22 best score = 0.7644907723855093\n",
      "INFO:__main__:k=23 best score = 0.7644907723855093\n",
      "INFO:__main__:k=24 best score = 0.7644907723855093\n",
      "INFO:__main__:k=25 best score = 0.7644907723855093\n",
      "INFO:__main__:k=26 best score = 0.7644907723855093\n",
      "INFO:__main__:k=27 best score = 0.7644907723855093\n",
      "INFO:__main__:k=28 best score = 0.7644907723855093\n",
      "INFO:__main__:k=29 best score = 0.7644907723855093\n",
      "INFO:__main__:k=30 best score = 0.7644907723855093\n",
      "INFO:__main__:k=31 best score = 0.7644907723855093\n",
      "INFO:__main__:k=32 best score = 0.7644907723855093\n",
      "INFO:__main__:k=33 best score = 0.7644907723855093\n",
      "INFO:__main__:k=34 best score = 0.7644907723855093\n",
      "INFO:__main__:k=35 best score = 0.7644907723855093\n",
      "INFO:__main__:k=36 best score = 0.7644907723855093\n",
      "INFO:__main__:k=37 best score = 0.7644907723855093\n",
      "INFO:__main__:k=38 best score = 0.7644907723855093\n",
      "INFO:__main__:k=39 best score = 0.7644907723855093\n",
      "INFO:__main__:k=40 best score = 0.7644907723855093\n",
      "INFO:__main__:k=41 best score = 0.7644907723855093\n",
      "INFO:__main__:k=42 best score = 0.7644907723855093\n",
      "INFO:__main__:k=43 best score = 0.7750170881749829\n",
      "INFO:__main__:k=44 best score = 0.7750170881749829\n",
      "INFO:__main__:k=45 best score = 0.7750170881749829\n",
      "INFO:__main__:k=46 best score = 0.7750170881749829\n",
      "INFO:__main__:k=47 best score = 0.7750170881749829\n",
      "INFO:__main__:k=48 best score = 0.7750170881749829\n",
      "INFO:__main__:k=49 best score = 0.7750170881749829\n",
      "INFO:__main__:global best score = 0.7750170881749829\n",
      "INFO:__main__:x_best = [17.36385697 10.76967948  4.11423957 20.05488364  3.40533574]\n",
      "INFO:__main__:best parameter = {'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_leaf_nodes': 20, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6833561175666438\n",
      "INFO:__main__:k=1 best score = 0.6833561175666438\n",
      "INFO:__main__:k=2 best score = 0.6988380041011618\n",
      "INFO:__main__:k=3 best score = 0.6988380041011618\n",
      "INFO:__main__:k=4 best score = 0.6988380041011618\n",
      "INFO:__main__:k=5 best score = 0.7253246753246753\n",
      "INFO:__main__:k=6 best score = 0.7253246753246753\n",
      "INFO:__main__:k=7 best score = 0.7330827067669173\n",
      "INFO:__main__:k=8 best score = 0.7330827067669173\n",
      "INFO:__main__:k=9 best score = 0.7330827067669173\n",
      "INFO:__main__:k=10 best score = 0.7330827067669173\n",
      "INFO:__main__:k=11 best score = 0.7330827067669173\n",
      "INFO:__main__:k=12 best score = 0.7383458646616542\n",
      "INFO:__main__:k=13 best score = 0.74107997265892\n",
      "INFO:__main__:k=14 best score = 0.74107997265892\n",
      "INFO:__main__:k=15 best score = 0.74107997265892\n",
      "INFO:__main__:k=16 best score = 0.74107997265892\n",
      "INFO:__main__:k=17 best score = 0.74107997265892\n",
      "INFO:__main__:k=18 best score = 0.74107997265892\n",
      "INFO:__main__:k=19 best score = 0.74107997265892\n",
      "INFO:__main__:k=20 best score = 0.74107997265892\n",
      "INFO:__main__:k=21 best score = 0.74107997265892\n",
      "INFO:__main__:k=22 best score = 0.7592617908407382\n",
      "INFO:__main__:k=23 best score = 0.7592617908407382\n",
      "INFO:__main__:k=24 best score = 0.7592617908407382\n",
      "INFO:__main__:k=25 best score = 0.7592617908407382\n",
      "INFO:__main__:k=26 best score = 0.7592617908407382\n",
      "INFO:__main__:k=27 best score = 0.7592617908407382\n",
      "INFO:__main__:k=28 best score = 0.7592617908407382\n",
      "INFO:__main__:k=29 best score = 0.7592617908407382\n",
      "INFO:__main__:k=30 best score = 0.7592617908407382\n",
      "INFO:__main__:k=31 best score = 0.7592617908407382\n",
      "INFO:__main__:k=32 best score = 0.7592617908407382\n",
      "INFO:__main__:k=33 best score = 0.7592617908407382\n",
      "INFO:__main__:k=34 best score = 0.7592617908407382\n",
      "INFO:__main__:k=35 best score = 0.7669172932330828\n",
      "INFO:__main__:k=36 best score = 0.7669172932330828\n",
      "INFO:__main__:k=37 best score = 0.7669172932330828\n",
      "INFO:__main__:k=38 best score = 0.7669172932330828\n",
      "INFO:__main__:k=39 best score = 0.7669172932330828\n",
      "INFO:__main__:k=40 best score = 0.7669172932330828\n",
      "INFO:__main__:k=41 best score = 0.7669172932330828\n",
      "INFO:__main__:k=42 best score = 0.7669172932330828\n",
      "INFO:__main__:k=43 best score = 0.7669172932330828\n",
      "INFO:__main__:k=44 best score = 0.7669172932330828\n",
      "INFO:__main__:k=45 best score = 0.7669172932330828\n",
      "INFO:__main__:k=46 best score = 0.7669172932330828\n",
      "INFO:__main__:k=47 best score = 0.7669172932330828\n",
      "INFO:__main__:k=48 best score = 0.7669172932330828\n",
      "INFO:__main__:k=49 best score = 0.7669172932330828\n",
      "INFO:__main__:global best score = 0.7669172932330828\n",
      "INFO:__main__:x_best = [20.57071681  8.8833264   3.08171891 18.50016953  3.24994588]\n",
      "INFO:__main__:best parameter = {'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_leaf_nodes': 18, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6672932330827066\n",
      "INFO:__main__:k=1 best score = 0.6672932330827066\n",
      "INFO:__main__:k=2 best score = 0.7408065618591934\n",
      "INFO:__main__:k=3 best score = 0.7408065618591934\n",
      "INFO:__main__:k=4 best score = 0.7408065618591934\n",
      "INFO:__main__:k=5 best score = 0.7408065618591934\n",
      "INFO:__main__:k=6 best score = 0.7431647300068353\n",
      "INFO:__main__:k=7 best score = 0.7431647300068353\n",
      "INFO:__main__:k=8 best score = 0.7431647300068353\n",
      "INFO:__main__:k=9 best score = 0.7436431989063569\n",
      "INFO:__main__:k=10 best score = 0.7436431989063569\n",
      "INFO:__main__:k=11 best score = 0.7436431989063569\n",
      "INFO:__main__:k=12 best score = 0.7436431989063569\n",
      "INFO:__main__:k=13 best score = 0.7436431989063569\n",
      "INFO:__main__:k=14 best score = 0.7436431989063569\n",
      "INFO:__main__:k=15 best score = 0.7458304853041695\n",
      "INFO:__main__:k=16 best score = 0.7458304853041695\n",
      "INFO:__main__:k=17 best score = 0.7458304853041695\n",
      "INFO:__main__:k=18 best score = 0.7566985645933014\n",
      "INFO:__main__:k=19 best score = 0.7566985645933014\n",
      "INFO:__main__:k=20 best score = 0.7566985645933014\n",
      "INFO:__main__:k=21 best score = 0.7566985645933014\n",
      "INFO:__main__:k=22 best score = 0.7566985645933014\n",
      "INFO:__main__:k=23 best score = 0.7566985645933014\n",
      "INFO:__main__:k=24 best score = 0.7566985645933014\n",
      "INFO:__main__:k=25 best score = 0.7566985645933014\n",
      "INFO:__main__:k=26 best score = 0.7566985645933014\n",
      "INFO:__main__:k=27 best score = 0.7566985645933014\n",
      "INFO:__main__:k=28 best score = 0.7566985645933014\n",
      "INFO:__main__:k=29 best score = 0.7566985645933014\n",
      "INFO:__main__:k=30 best score = 0.7566985645933014\n",
      "INFO:__main__:k=31 best score = 0.7566985645933014\n",
      "INFO:__main__:k=32 best score = 0.7566985645933014\n",
      "INFO:__main__:k=33 best score = 0.7566985645933014\n",
      "INFO:__main__:k=34 best score = 0.7566985645933014\n",
      "INFO:__main__:k=35 best score = 0.7566985645933014\n",
      "INFO:__main__:k=36 best score = 0.7566985645933014\n",
      "INFO:__main__:k=37 best score = 0.7566985645933014\n",
      "INFO:__main__:k=38 best score = 0.7566985645933014\n",
      "INFO:__main__:k=39 best score = 0.7566985645933014\n",
      "INFO:__main__:k=40 best score = 0.7566985645933014\n",
      "INFO:__main__:k=41 best score = 0.7566985645933014\n",
      "INFO:__main__:k=42 best score = 0.7566985645933014\n",
      "INFO:__main__:k=43 best score = 0.7566985645933014\n",
      "INFO:__main__:k=44 best score = 0.7566985645933014\n",
      "INFO:__main__:k=45 best score = 0.7566985645933014\n",
      "INFO:__main__:k=46 best score = 0.7566985645933014\n",
      "INFO:__main__:k=47 best score = 0.7566985645933014\n",
      "INFO:__main__:k=48 best score = 0.7618591934381408\n",
      "INFO:__main__:k=49 best score = 0.7618591934381408\n",
      "INFO:__main__:global best score = 0.7618591934381408\n",
      "INFO:__main__:x_best = [12.6540914   5.63992798  2.95029564 21.94875408  3.89799456]\n",
      "INFO:__main__:best parameter = {'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_leaf_nodes': 21, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:k=0 best score = 0.6859193438140807\n",
      "INFO:__main__:k=1 best score = 0.6860218728639782\n",
      "INFO:__main__:k=2 best score = 0.6860218728639782\n",
      "INFO:__main__:k=3 best score = 0.6860218728639782\n",
      "INFO:__main__:k=4 best score = 0.7354408749145591\n",
      "INFO:__main__:k=5 best score = 0.7354408749145591\n",
      "INFO:__main__:k=6 best score = 0.7354408749145591\n",
      "INFO:__main__:k=7 best score = 0.7354408749145591\n",
      "INFO:__main__:k=8 best score = 0.7354408749145591\n",
      "INFO:__main__:k=9 best score = 0.7354408749145591\n",
      "INFO:__main__:k=10 best score = 0.7354408749145591\n",
      "INFO:__main__:k=11 best score = 0.7354408749145591\n",
      "INFO:__main__:k=12 best score = 0.7354408749145591\n",
      "INFO:__main__:k=13 best score = 0.7487354750512646\n",
      "INFO:__main__:k=14 best score = 0.7487354750512646\n",
      "INFO:__main__:k=15 best score = 0.7618591934381408\n",
      "INFO:__main__:k=16 best score = 0.7618591934381408\n",
      "INFO:__main__:k=17 best score = 0.7618591934381408\n",
      "INFO:__main__:k=18 best score = 0.7618591934381408\n",
      "INFO:__main__:k=19 best score = 0.7618591934381408\n",
      "INFO:__main__:k=20 best score = 0.7618591934381408\n",
      "INFO:__main__:k=21 best score = 0.7618591934381408\n",
      "INFO:__main__:k=22 best score = 0.7618591934381408\n",
      "INFO:__main__:k=23 best score = 0.7618591934381408\n",
      "INFO:__main__:k=24 best score = 0.7618591934381408\n",
      "INFO:__main__:k=25 best score = 0.7618591934381408\n",
      "INFO:__main__:k=26 best score = 0.7618591934381408\n",
      "INFO:__main__:k=27 best score = 0.7618591934381408\n",
      "INFO:__main__:k=28 best score = 0.7618591934381408\n",
      "INFO:__main__:k=29 best score = 0.7618591934381408\n",
      "INFO:__main__:k=30 best score = 0.7618591934381408\n",
      "INFO:__main__:k=31 best score = 0.7618591934381408\n",
      "INFO:__main__:k=32 best score = 0.7618591934381408\n",
      "INFO:__main__:k=33 best score = 0.7618591934381408\n",
      "INFO:__main__:k=34 best score = 0.7618591934381408\n",
      "INFO:__main__:k=35 best score = 0.7618591934381408\n",
      "INFO:__main__:k=36 best score = 0.7618591934381408\n",
      "INFO:__main__:k=37 best score = 0.7618591934381408\n",
      "INFO:__main__:k=38 best score = 0.7618591934381408\n",
      "INFO:__main__:k=39 best score = 0.7618591934381408\n",
      "INFO:__main__:k=40 best score = 0.7618591934381408\n",
      "INFO:__main__:k=41 best score = 0.7618591934381408\n",
      "INFO:__main__:k=42 best score = 0.7618591934381408\n",
      "INFO:__main__:k=43 best score = 0.7823308270676692\n",
      "INFO:__main__:k=44 best score = 0.7823308270676692\n",
      "INFO:__main__:k=45 best score = 0.7823308270676692\n",
      "INFO:__main__:k=46 best score = 0.7823308270676692\n",
      "INFO:__main__:k=47 best score = 0.7823308270676692\n",
      "INFO:__main__:k=48 best score = 0.7823308270676692\n",
      "INFO:__main__:k=49 best score = 0.7823308270676692\n",
      "INFO:__main__:global best score = 0.7823308270676692\n",
      "INFO:__main__:x_best = [10.98629674  4.58154946  3.47910935 30.98559679  3.0122043 ]\n",
      "INFO:__main__:best parameter = {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_leaf_nodes': 30, 'max_features': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[13.927955150604248, 17.42077612876892, 17.16262412071228, 17.09074902534485, 18.08102297782898, 17.651416063308716, 21.499034881591797, 20.995457887649536, 18.162853956222534, 21.005765676498413]\n"
     ]
    }
   ],
   "source": [
    "Grid_times = []\n",
    "Random_times = []\n",
    "DE_times = []\n",
    "\n",
    "Grid_paras = []\n",
    "Random_paras = []\n",
    "DE_paras = []\n",
    "\n",
    "DE_scores = []\n",
    "\n",
    "for i in range(len(search_spaces_for_DE)):\n",
    "    # Grid Search \n",
    "#     time_start=time.time()\n",
    "#     clf = GridSearchCV(RandomForestClassifier(random_state = 1), search_spaces[i], cv = 5)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     time_end=time.time()\n",
    "#     Grid_times.append(time_end-time_start)\n",
    "    \n",
    "    # Add paras\n",
    "#     Grid_paras.append(clf.best_params_)\n",
    "    \n",
    "    # Randomised Search\n",
    "#     time_start=time.time()\n",
    "#     clf = RandomizedSearchCV(RandomForestClassifier(random_state = 1), search_spaces[i], cv = 5, n_iter = 100)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     time_end=time.time()\n",
    "#     Random_times.append(time_end-time_start)\n",
    "    \n",
    "    # Add paras\n",
    "#     Random_paras.append(clf.best_params_)\n",
    "    \n",
    "    # DE\n",
    "    tuner = HyperTuner(model= RandomForestClassifier(random_state =1), space=search_spaces_for_DE[i])\n",
    "    time_start=time.time()\n",
    "    best_param = tuner.tuning(eval_function=accuracy_score, x=X_train, t=y_train, minimize=False)\n",
    "    time_end=time.time()\n",
    "    DE_times.append(time_end-time_start)\n",
    "    logger.info('best parameter = {}'.format(best_param))\n",
    "    \n",
    "    paras = list(best_param.values())\n",
    "    \n",
    "    \n",
    "    # Add paras\n",
    "    DE_paras.append(best_param)\n",
    "    # Add accuracies\n",
    "    clf = RandomForestClassifier(max_depth = paras[0], max_leaf_nodes = paras[3], max_features = paras[4], min_samples_leaf = paras[2], min_samples_split = paras[1], random_state = 1) \n",
    "    clf.fit(X_train, y_train)\n",
    "    DE_scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# print(Grid_times)\n",
    "# print(Random_times)\n",
    "print(DE_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3488372093023256, 0.5581395348837209, 0.5348837209302325, 0.6046511627906976, 0.627906976744186, 0.6744186046511628, 0.6976744186046512, 0.6744186046511628, 0.6744186046511628, 0.6976744186046512]\n"
     ]
    }
   ],
   "source": [
    "print(DE_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(Grid_times, label = 'GridSearchCV')\n",
    "# plt.plot(Random_times, label = 'RandomisedSearchCV')\n",
    "plt.plot(DE_times, label = 'SaDE++')\n",
    "plt.legend(loc = [1, 0])\n",
    "plt.xticks(range(0, 4))\n",
    "plt.xlabel('Search Space')\n",
    "plt.ylabel('Time consumption (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 2, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 4, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2}, {'max_depth': 6, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 8, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 7}]\n",
      "[{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 2}, {'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': None, 'max_depth': 4}, {'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'max_depth': 6}, {'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 7}]\n",
      "[{'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}, {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}, {'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None}, {'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}]\n"
     ]
    }
   ],
   "source": [
    "print(Grid_paras)\n",
    "print(Random_paras)\n",
    "print(DE_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, None, 1, 2]\n",
      "[2, 1, None, 2]\n",
      "[2, 2, 1, None]\n",
      "[4, None, 3, 2]\n",
      "[5, 3, None, 4]\n",
      "[4, 5, 2, None]\n",
      "[6, None, 2, 2]\n",
      "[2, 3, None, 6]\n",
      "[6, 3, 3, None]\n",
      "[8, None, 3, 7]\n",
      "[9, 1, None, 7]\n",
      "[7, 5, 1, None]\n"
     ]
    }
   ],
   "source": [
    "Grid_scores = []\n",
    "Random_scores = [] \n",
    "DE_scores = []\n",
    "\n",
    "for i in range(len(Grid_paras)):\n",
    "    paras = list(Grid_paras[i].values())\n",
    "    print(paras)\n",
    "    clf = RandomForestClassifier(max_depth = paras[0], max_features = paras[1], min_samples_leaf = paras[2], min_samples_split = paras[3], random_state = 1) \n",
    "    clf.fit(X_train, y_train)\n",
    "    Grid_scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    paras = list(Random_paras[i].values())\n",
    "    print(paras)\n",
    "    clf = RandomForestClassifier(max_depth = paras[3], max_features = paras[2], min_samples_leaf = paras[1], min_samples_split = paras[0], random_state = 1) \n",
    "    clf.fit(X_train, y_train)\n",
    "    Random_scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    paras = list(DE_paras[i].values())\n",
    "    print(paras)\n",
    "    clf = RandomForestClassifier(max_depth = paras[0], max_features = paras[3], min_samples_leaf = paras[2], min_samples_split = paras[1], random_state = 1) \n",
    "    clf.fit(X_train, y_train)\n",
    "    DE_scores.append(clf.score(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a248aa0f0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Grid_scores, label = 'GridSearchCV')\n",
    "plt.plot(Random_scores, label = 'RandomisedSearchCV')\n",
    "plt.plot(DE_scores, label = 'SaDE++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
